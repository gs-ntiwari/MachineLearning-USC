{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Homework 1\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Do not import other libraries. You are only allowed to use Math, Numpy, Scipy packages which are already imported in the file.\n",
    "- Please follow the type annotations. There are some type annotations of the parameters of function calls and return values. Please use Python 3.5 or 3.6 (for full support of typing annotations). You can use Numpy/Scipy inside the function.  You have to make the functions’ return values match the required type.\n",
    "- In this programming assignment you will to implement **k-Nearest Neighbours and Decision Tree**. We provide the bootstrap code and you are expected to complete the **classes** and **functions**.\n",
    "- Download all files of PA1 from Vocareum and save in the same folder.\n",
    "- Only modifications in files {`hw1_knn.py`, `hw1_dt.py`, `utils.py`} will be accepted and graded. All other modifications will be ignored. Submit those three files on Vocareum once you have finished. Which means you need to delete unnecessary files before you submit your work on Vocareum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Office Hour:\n",
    "```\n",
    "Week 2\n",
    "Jan. 14th Monday\tLVL 2nd Floor-201B\t1:00pm to 3:00pm\tCheng-Ju Lin chengjul@usc.edu\n",
    "Jan. 15th Tuesday\tLVL 2nd Floor-201B\t1:00pm to 3:00pm\tYang Fang yangfang@usc.edu\n",
    "Jan. 17th Thursday\tLVL 2nd Floor-202B\t10:00am to 12:00pm\tYixian Di yixiandi@usc.edu\n",
    "Week 3\n",
    "Jan. 22th Tuesday\tSAL 125         \t11:00am to 1:00pm\tAshir Alam ashirala@usc.edu\n",
    "Jan. 23th Wednesday\tSAL 125         \t11:00am to 1:00pm\tAshir Alam ashirala@usc.edu\n",
    "Jan. 24th Thursday\tLVL 2nd Floor-202B\t10:00am to 12:00pm\tYixian Di yixiandi@usc.edu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: K-nearest neighbor (KNN) for binary classification (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some notes\n",
    "\n",
    "In this task, we will use four distance functions: (we removed the vector symbol for simplicity)\n",
    "\n",
    "- Euclidean distance:  $$d(x, y) = \\sqrt{\\langle x - y, x - y \\rangle}$$\n",
    "- Inner product distance: $$d(x, y ) = \\langle x, y \\rangle$$\n",
    "- Gaussian kernel distance: \n",
    "    $$d(x, y ) = - \\exp({−\\frac 12 \\langle x - y, x - y \\rangle}) $$\n",
    "- Cosine Distance: $$d(x, y) =\\cos(\\theta )={\\mathbf {x} \\cdot \\mathbf {y}  \\over \\|\\mathbf {x} \\|\\|\\mathbf {y} \\|}$$\n",
    "\n",
    "F1-score is a important metric for binary classification, as sometimes the accuracy metric has the false positive (a good example is in MLAPP book 2.2.3.1 “Example: medical diagnosis”, Page 29).\n",
    "We have provided a basic definition. For more you can read 5.7.2.3 from MLAPP book.\n",
    "\n",
    "<img src=\"F1Score.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1.1 Distance Functions\n",
    "\n",
    "Implement the class in file hw1_knn.py\n",
    "    the functions in utils.py    \n",
    "    - f1_score\n",
    "    - euclidean_distance\n",
    "    - inner_product_distance\n",
    "    - gaussian_kernel_distance\n",
    "    - cosine distance\n",
    "\n",
    "Simply follow the formula above and finish all these function. You are not allowed to call any package that we did not import for you.\n",
    "    \n",
    "### Part 1.1.2 KNN Class\n",
    "\n",
    "There are following functions you need to implement in KNN class:\n",
    "\n",
    "1.def train(self, features: List[List[float]], labels: List[int])\n",
    "     \n",
    "In this function, features are simply all training data which is a 2D list with float. For example, if the data looks like the following: Student 1 with features age 25, grade 3.8 and labeled as 0, Student 2 with features age 22, grade 3.0 and labeled as 1, then the feature data should be [ [25.0, 3.8], [22.0,3.0] ], thus the coresponding label is [0,1]\n",
    "    \n",
    "For KNN, the training process is just loading all the training data. Thus, all you need to do in this function is create some local variable in KNN class to store these data so you can use the data in later process.\n",
    "    \n",
    "2.def get_k_neighbors(self, point: List[float]) -> List[int]:\n",
    "\n",
    "This function takes one single data point and ask you to find the nearest k neighbours in the training set. You already have your k value, distance function and you just stored all training data in KNN class with the train function. \n",
    "\n",
    "This function need to return a list of labels of all k neighours.\n",
    "\n",
    "3.def predict(self, features: List[List[float]]) -> List[int]\n",
    "\n",
    "The predict function take another 2D list which is all testing data point, Similar to those from train function. In this function, you need process every testing data point, reuse the get_k_neighbours function to find the nearest k neighbours for each testing data point, find the majority of labels for these neighbours as the predict label for that testing data point. Thus, you will get N predicted label for N testing data point.\n",
    "\n",
    "This function need to return a list of predicted labels for all testing data points.\n",
    "\n",
    "\n",
    "Once you finished everything above, you can run the next cell to continue.\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from hw1_knn import KNN\n",
    "from utils import euclidean_distance, gaussian_kernel_distance, inner_product_distance, cosine_sim_distance\n",
    "from utils import f1_score, model_selection_without_normalization, model_selection_with_transformation\n",
    "distance_funcs = {\n",
    "    'euclidean': euclidean_distance,\n",
    "    'gaussian': gaussian_kernel_distance,\n",
    "    'inner_prod': inner_product_distance,\n",
    "    'cosine_dist': cosine_sim_distance,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import data_processing\n",
    "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing()\n",
    "#Xtrain, ytrain\n",
    "\n",
    "print(cosine_sim_distance([0, 1, 1, 1], [1, 0, 1, 1]))\n",
    "#print(inner_product_distance([500005123],[500005123]))\n",
    "\n",
    "import utils as utils\n",
    "utils.print_tree(None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1.3 Model selection \n",
    "\n",
    "In this section, you need to implement the following function:\n",
    "\n",
    "1.def model_selection_without_normalization(distance_funcs, Xtrain, ytrain, Xval, yval)\n",
    "\n",
    "In this part, you should try different distance function you implemented in part 1.1, and find the best k. Use k range from 1 to 30 and increment by 2. We will use f1-score to compare different models. \n",
    "\n",
    "THis function take the following parameter:\n",
    "\n",
    "distance_funcs: dictionary of distance funtion you will use to calculate the distance. Make sure you loop over all distance function for each data point and each k value.\n",
    "\n",
    "Xtrain: List[List[int]] training data set to train your KNN model\n",
    "\n",
    "ytrain: List[int] train labels to train your KNN model\n",
    "\n",
    "Xval: List[List[int]] validation data set you will use on your KNN predict function to produce predicted labels and tune k and distance function.\n",
    "\n",
    "yval: List[int] validation labels\n",
    "\n",
    "This function need to return the following:\n",
    "\n",
    "best_model: an instance of KNN\n",
    "\n",
    "best_k: best k choosed for best_model\n",
    "\n",
    "best_func: name of best function choosed for best_model\n",
    "\n",
    "Thus, the function only return one set of  model, k and function.\n",
    "\n",
    "Once you finished everything above, you can run the next cell to continue.\n",
    "\n",
    "Note: When there is a tie, chose model based on the following priorities:\n",
    "Then check distance function  [euclidean > gaussian > inner_prod > cosine_dist];\n",
    "If they have same distance fuction, choose model who have a less k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_k, best_function = model_selection_without_normalization(distance_funcs, Xtrain, ytrain, Xval, yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Data transformation\n",
    "\n",
    "We are going to add one more step (data transformation) in the data processing part and see how it works. \n",
    "Sometimes, normalization plays an important role to make a machine learning model work (check term “Feature scaling” in wiki).\n",
    "\n",
    "Here, we take two different data transformation approaches.\n",
    "\n",
    "#### Normalizing the feature vector \n",
    "\n",
    "This one is simple but some times may work well. Given a feature vector $x$, the normalized feature vector is given by \n",
    "\n",
    "$$ x' = \\frac x {\\sqrt{\\langle x, x \\rangle}} $$\n",
    "If a vector is a all-zero vector, we let the normalized vector also be a all-zero vector.\n",
    "\n",
    "\n",
    "#### Min-max scaling the feature matrix\n",
    "\n",
    "The above normalization is data independent, that is to say, the output of the normalization function doesn’t depend on the rest training data. However, sometimes it would be helpful to do data dependent normalization. One thing to note is that, when doing data dependent normalization, we can only use training data, as the test data is assumed to be unknown during training (at least for most classification tasks).\n",
    "\n",
    "The min-max scaling works as follows: after min-max scaling, all values of training data’s feature vectors are in the given range.\n",
    "Note that this doesn’t mean the values of the validation/test data’s fea- tures are all in that range, because the validation/test data may have dif- ferent distribution as the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the functions in utils.py  \n",
    "\n",
    "1.normalize\n",
    "    \n",
    "normalize the feature vector for each sample . For example, if the input features = [[3, 4], [1, -1], [0, 0]], the output should be [[0.6, 0.8], [0.707107, -0.707107], [0, 0]]\n",
    "        \n",
    "2.min_max_scale\n",
    "\n",
    "normalize the feature vector for each sample . For example, if the input features = [[2, -1], [-1, 5], [0, 0]], the output should be [[1, 0], [0, 1], [0.333333, 0.16667]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(best_model, best_k, best_function)\n",
    "from utils import NormalizationScaler, MinMaxScaler\n",
    "\n",
    "scaling_classes = {\n",
    "    'min_max_scale': MinMaxScaler,\n",
    "    'normalize': NormalizationScaler,\n",
    "}\n",
    "array=[[3, 4], [1, -1], [0, 0]]\n",
    "n=NormalizationScaler()\n",
    "\n",
    "print(n(array))\n",
    "'''\n",
    "m=MinMaxScaler()\n",
    "result=m([[1, 2, 2],[1,0,0]])\n",
    "print(result)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection\n",
    "\n",
    "This part will be similar to Part 1.1.3 except before pass your traing and validation data to KNN model, you need to create the normalized data using these two scaller to transform your data, both training and validation. Again, we will use f1-score to compare different models.\n",
    "\n",
    "1.def model_selection_with_transformation(distance_funcs, scaling_classes, Xtrain, ytrain, Xval, yval)\n",
    "\n",
    "The function take the following input:\n",
    "\n",
    "distance_funcs: dictionary of distance funtion you will use to calculate the distance. Make sure you loop over all distance function for each data point and each k value.\n",
    "\n",
    "scaling_classes: diction of scalers you will use to normalized your data\n",
    "\n",
    "Xtrain: List[List[int]] training data set to train your KNN model\n",
    "\n",
    "ytrain: List[int] train labels to train your KNN model\n",
    "\n",
    "Xval: List[List[int]] validation data set you will use on your KNN predict function to produce predicted labels and tune your k, distance function and scaler.\n",
    "\n",
    "yval: List[int] validation labels\n",
    "\n",
    "This function need to return the following:\n",
    "\n",
    "best_model: an instance of KNN\n",
    "\n",
    "best_k: best k choosed for best_model\n",
    "\n",
    "best_func: name of best function choosed for best_model\n",
    "\n",
    "best_scaler: name of the scaler choosed for best_model\n",
    "\n",
    "Thus, the function only return one set of  model, k, function name and scaler name.\n",
    "\n",
    "Once you finished everything above, you can run the next cell to continue.\n",
    "\n",
    "Note: When there is a tie, chose model based on the following priorities:\n",
    "For normalization, [min_max_scale > normalize];\n",
    "Then check distance function  [euclidean > gaussian > inner_prod > cosine_dist];\n",
    "If they have same distance fuction, choose model who have a less k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_k, best_function, best_scaler = model_selection_with_transformation(distance_funcs, scaling_classes, Xtrain, ytrain, Xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model, best_k, best_function, best_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guideline for KNN\n",
    "1. UTILS function: 15 points <br>\n",
    "\n",
    "2. 2 functions in hw1_Knn (10 points- 5 each) <br>\n",
    "\n",
    "3. Finding best K before scaling - 10 points <br>\n",
    "\n",
    "4. Finding best K after scaling - 10 points <br>\n",
    "\n",
    "5. Doing classification of the data - 5 points <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Decision Tree (50 points)\n",
    "- Remember from lecture, we learned that we can use decision tree to solve classification and regression problem. Mostly we focus on classification.\n",
    "- In problem 1 we used KNN to do classification. We could use decision tree algorithm to do the same job.\n",
    "- For Decision Tree, we will implement ID3 algorithm. It's garanteed that all features are discrete.\n",
    "## Part 2.1 Implementation\n",
    "### 2.1.1\n",
    "- In ID3 algorithm, we use Entropy to measure the uncertainty in the data set. We use Information Gain to measure the quality of a split.\n",
    "- Entropy: H(S)=\\\\(\\sum_{x∈X} -p(x)log_2p(x)\\\\)\n",
    "- Information_Gain: IG(S,A) = H(S)-\\\\(\\sum_{t∈T}p(t)H(T)\\\\) = H(S) - H(S|A)\n",
    "- see more detail on [ID3 Algorithm](https://en.wikipedia.org/wiki/ID3_algorithm)\n",
    "In this section, you need to implement Information_Gain function on utils.py.\n",
    "```\n",
    "def Information_Gain(S, branches):\n",
    "# calculate information_gain according to branches seperated by one feature\n",
    "# input:\n",
    "    -S: float Entropy of current state\n",
    "    -branches: List[List[int]] for a specific attribute, number of cases belongs to each attribut value and class, num_attribute_values*num_classes\n",
    "# return: float\n",
    "```\n",
    "### 2.1.2 \n",
    "- In ID3 algorithm, we use the largest information gain to split the set S. Please consult the Lecture 2 notes page 23.\n",
    "\n",
    "\n",
    "- Implement TreeNode split function and TreeNode predict function in hw1_dt.py:\n",
    "    - TreeNode.split<br>\n",
    "    \n",
    "    In the TreeNode class, the features variable means all the points in current TreeNode, and the labels variable means the corresponding labels for all data. The children variable is a list of TreeNode after split the current node based on the best attributs. This should be a recursive process that once we call the split function, the TreeNode will keep spliting untill we get the whole tree structure.\n",
    "    \n",
    "    **Note: when there is a tie of information gain when comparing the attributes, always choose the attribute which has more attribute values. If they are all same, use the one with small index. Also build your child list with increasing order of attribute value.**\n",
    "    - TreeNode.predict\n",
    "    \n",
    "    This function will be called once we create the tree structure by the split function. It will take one single data point as a parameter, your code should process that data point and go through your tree to a leaf and make prediction.\n",
    "    Thus, this function need to return a predicted lable.\n",
    "   \n",
    "\n",
    "- You no longer need to implement Decision Tree predict and train function in hw1_dt.py:\n",
    "    - DecisionTree.train\n",
    "    - DecisionTree.predict\n",
    "    \n",
    "  We will provide these two function in the statercode. Reading the train and predict function should help you understanding funcitons that you need to implement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2 Sanity Test\n",
    "Do the following steps, as a simple test to check your algorithm works well\n",
    "- Load training data (features and values) from function data.sample_decision_tree_data.\n",
    "- Create a Decision Tree based on training data.\n",
    "- Load test data from function data.sample_decision_tree_test.\n",
    "- Test the prediction function of your algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ig: 0.0352880339 max_ig -1\n",
      "ig: 0.0239809946 max_ig 0.0352880339\n",
      "ig: 0.0052592934 max_ig 0.0352880339\n",
      "ig: 0.2173839244 max_ig 0.0352880339\n",
      "ig: 0.0323794088 max_ig 0.2173839244\n",
      "ig: 0.2553005935 max_ig 0.2173839244\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0365769344 max_ig -1\n",
      "ig: 0.0423794365 max_ig 0.0365769344\n",
      "ig: 0.0092469462 max_ig 0.0423794365\n",
      "ig: 0.2877521893 max_ig 0.0423794365\n",
      "ig: 0.1068535729 max_ig 0.2877521893\n",
      "ig: 0.0 max_ig 0.2877521893\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0811219906 max_ig -1\n",
      "ig: 0.078364898 max_ig 0.0811219906\n",
      "ig: 0.0105741046 max_ig 0.0811219906\n",
      "ig: 0.0 max_ig 0.0811219906\n",
      "ig: 0.1903322492 max_ig 0.0811219906\n",
      "ig: 0.0 max_ig 0.1903322492\n",
      "ig: 0.2331630298 max_ig -1\n",
      "ig: 0.075211421 max_ig 0.2331630298\n",
      "ig: 0.016825722 max_ig 0.2331630298\n",
      "ig: 0.0 max_ig 0.2331630298\n",
      "ig: 0.0 max_ig 0.2331630298\n",
      "ig: 0.0 max_ig 0.2331630298\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.2896917933 max_ig 0.0\n",
      "ig: 0.0710768803 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.4854752972 max_ig 0.0\n",
      "ig: 0.019973094 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0468606807 max_ig -1\n",
      "ig: 0.0959207592 max_ig 0.0468606807\n",
      "ig: 0.341075085 max_ig 0.0959207592\n",
      "ig: 0.0 max_ig 0.341075085\n",
      "ig: 0.0 max_ig 0.341075085\n",
      "ig: 0.0 max_ig 0.341075085\n",
      "ig: 0.1709505945 max_ig -1\n",
      "ig: 0.1319146419 max_ig 0.1709505945\n",
      "ig: 0.0 max_ig 0.1709505945\n",
      "ig: 0.0 max_ig 0.1709505945\n",
      "ig: 0.0 max_ig 0.1709505945\n",
      "ig: 0.0 max_ig 0.1709505945\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.3774437511 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.3112781245 max_ig -1\n",
      "ig: 0.1225562489 max_ig 0.3112781245\n",
      "ig: 0.0 max_ig 0.3112781245\n",
      "ig: 0.0 max_ig 0.3112781245\n",
      "ig: 0.0 max_ig 0.3112781245\n",
      "ig: 0.0 max_ig 0.3112781245\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.5 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.1138187832 max_ig -1\n",
      "ig: 0.5916727786 max_ig 0.1138187832\n",
      "ig: 0.0 max_ig 0.5916727786\n",
      "ig: 0.0 max_ig 0.5916727786\n",
      "ig: 0.0 max_ig 0.5916727786\n",
      "ig: 0.0 max_ig 0.5916727786\n",
      "ig: 0.2516291674 max_ig -1\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.2516291674 max_ig -1\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.1426902795 max_ig -1\n",
      "ig: 0.1021871709 max_ig 0.1426902795\n",
      "ig: 0.0 max_ig 0.1426902795\n",
      "ig: 0.0 max_ig 0.1426902795\n",
      "ig: 0.0 max_ig 0.1426902795\n",
      "ig: 0.0 max_ig 0.1426902795\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.1225562489 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.1370311279 max_ig -1\n",
      "ig: 0.1370311279 max_ig 0.1370311279\n",
      "ig: 0.0415585965 max_ig 0.1370311279\n",
      "ig: 0.0 max_ig 0.1370311279\n",
      "ig: 0.0 max_ig 0.1370311279\n",
      "ig: 0.0 max_ig 0.1370311279\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.2284788098 max_ig 0.0\n",
      "ig: 0.1548558344 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.3219280949 max_ig 0.0\n",
      "ig: 0.3219280949 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.2365617118 max_ig 0.0\n",
      "ig: 0.0817041659 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0648050637 max_ig -1\n",
      "ig: 0.0842732561 max_ig 0.0648050637\n",
      "ig: 0.0375427094 max_ig 0.0842732561\n",
      "ig: 0.0 max_ig 0.0842732561\n",
      "ig: 0.2206411512 max_ig 0.0842732561\n",
      "ig: 0.0 max_ig 0.2206411512\n",
      "ig: 0.1253335689 max_ig -1\n",
      "ig: 0.057238092 max_ig 0.1253335689\n",
      "ig: 0.1104707775 max_ig 0.1253335689\n",
      "ig: 0.0 max_ig 0.1253335689\n",
      "ig: 0.0 max_ig 0.1253335689\n",
      "ig: 0.0 max_ig 0.1253335689\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.1143933723 max_ig 0.0\n",
      "ig: 0.1359275702 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.5087256744 max_ig 0.0\n",
      "ig: 0.1720797085 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0679272158 max_ig -1\n",
      "ig: 0.1034106446 max_ig 0.0679272158\n",
      "ig: 0.250066483 max_ig 0.1034106446\n",
      "ig: 0.0 max_ig 0.250066483\n",
      "ig: 0.0 max_ig 0.250066483\n",
      "ig: 0.0 max_ig 0.250066483\n",
      "ig: 0.1535654389 max_ig -1\n",
      "ig: 0.1142742112 max_ig 0.1535654389\n",
      "ig: 0.0 max_ig 0.1535654389\n",
      "ig: 0.0 max_ig 0.1535654389\n",
      "ig: 0.0 max_ig 0.1535654389\n",
      "ig: 0.0 max_ig 0.1535654389\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.419973094 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.2516291674 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.1952373016 max_ig -1\n",
      "ig: 0.1952373016 max_ig 0.1952373016\n",
      "ig: 0.0 max_ig 0.1952373016\n",
      "ig: 0.0 max_ig 0.1952373016\n",
      "ig: 0.0 max_ig 0.1952373016\n",
      "ig: 0.0 max_ig 0.1952373016\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.3059584929 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.2516291674 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.2516291674 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0548246486 max_ig -1\n",
      "ig: 0.0713043522 max_ig 0.0548246486\n",
      "ig: 0.0 max_ig 0.0713043522\n",
      "ig: 0.0 max_ig 0.0713043522\n",
      "ig: 0.0 max_ig 0.0713043522\n",
      "ig: 0.0 max_ig 0.0713043522\n",
      "ig: 0.019973094 max_ig -1\n",
      "ig: 0.0 max_ig 0.019973094\n",
      "ig: 0.0 max_ig 0.019973094\n",
      "ig: 0.0 max_ig 0.019973094\n",
      "ig: 0.0 max_ig 0.019973094\n",
      "ig: 0.0 max_ig 0.019973094\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.3112781245 max_ig -1\n",
      "ig: 0.0 max_ig 0.3112781245\n",
      "ig: 0.0 max_ig 0.3112781245\n",
      "ig: 0.0 max_ig 0.3112781245\n",
      "ig: 0.0 max_ig 0.3112781245\n",
      "ig: 0.0 max_ig 0.3112781245\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.4036364512 max_ig -1\n",
      "ig: 0.374229506 max_ig 0.4036364512\n",
      "ig: 0.0 max_ig 0.4036364512\n",
      "ig: 0.0 max_ig 0.4036364512\n",
      "ig: 0.0 max_ig 0.4036364512\n",
      "ig: 0.0 max_ig 0.4036364512\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.3112781245 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 1.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.1711653009 max_ig -1\n",
      "ig: 0.2481483744 max_ig 0.1711653009\n",
      "ig: 0.0295915035 max_ig 0.2481483744\n",
      "ig: 0.0 max_ig 0.2481483744\n",
      "ig: 0.0 max_ig 0.2481483744\n",
      "ig: 0.0 max_ig 0.2481483744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ig: 0.4247120235 max_ig -1\n",
      "ig: 0.0 max_ig 0.4247120235\n",
      "ig: 0.1359390015 max_ig 0.4247120235\n",
      "ig: 0.0 max_ig 0.4247120235\n",
      "ig: 0.0 max_ig 0.4247120235\n",
      "ig: 0.0 max_ig 0.4247120235\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.4581058952 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.5709505945 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.5709505945 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.3166890883 max_ig -1\n",
      "ig: 0.0 max_ig 0.3166890883\n",
      "ig: 0.459147917 max_ig 0.3166890883\n",
      "ig: 0.0 max_ig 0.459147917\n",
      "ig: 0.0 max_ig 0.459147917\n",
      "ig: 0.0 max_ig 0.459147917\n",
      "ig: 0.2516291674 max_ig -1\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig 0.2516291674\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.3178113758 max_ig -1\n",
      "ig: 0.0 max_ig 0.3178113758\n",
      "ig: 0.0681873375 max_ig 0.3178113758\n",
      "ig: 0.0 max_ig 0.3178113758\n",
      "ig: 0.0 max_ig 0.3178113758\n",
      "ig: 0.0 max_ig 0.3178113758\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.3333333333 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0967002241 max_ig -1\n",
      "ig: 0.0370671996 max_ig 0.0967002241\n",
      "ig: 0.0141857406 max_ig 0.0967002241\n",
      "ig: 0.5233228055 max_ig 0.0967002241\n",
      "ig: 0.1077477259 max_ig 0.5233228055\n",
      "ig: 0.0 max_ig 0.5233228055\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.2196095245 max_ig -1\n",
      "ig: 0.1366435761 max_ig 0.2196095245\n",
      "ig: 0.0492681269 max_ig 0.2196095245\n",
      "ig: 0.0 max_ig 0.2196095245\n",
      "ig: 0.2027813536 max_ig 0.2196095245\n",
      "ig: 0.0 max_ig 0.2196095245\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.298820395 max_ig 0.0\n",
      "ig: 0.1033492974 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.216048887 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.3417923256 max_ig 0.0\n",
      "ig: 0.0983400505 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.5387921088 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.3112781245 max_ig 0.0\n",
      "ig: 0.0018989204 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0254666528 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.1532321566 max_ig -1\n",
      "ig: 0.0649148142 max_ig 0.1532321566\n",
      "ig: 0.085080833 max_ig 0.1532321566\n",
      "ig: 0.0 max_ig 0.1532321566\n",
      "ig: 0.1844602578 max_ig 0.1532321566\n",
      "ig: 0.0 max_ig 0.1844602578\n",
      "ig: 0.1340357996 max_ig -1\n",
      "ig: 0.0733356344 max_ig 0.1340357996\n",
      "ig: 0.5070160445 max_ig 0.1340357996\n",
      "ig: 0.0 max_ig 0.5070160445\n",
      "ig: 0.0 max_ig 0.5070160445\n",
      "ig: 0.0 max_ig 0.5070160445\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.2954618442 max_ig -1\n",
      "ig: 0.419973094 max_ig 0.2954618442\n",
      "ig: 0.0 max_ig 0.419973094\n",
      "ig: 0.0 max_ig 0.419973094\n",
      "ig: 0.0 max_ig 0.419973094\n",
      "ig: 0.0 max_ig 0.419973094\n",
      "ig: 0.5849625007 max_ig -1\n",
      "ig: 0.0 max_ig 0.5849625007\n",
      "ig: 0.0 max_ig 0.5849625007\n",
      "ig: 0.0 max_ig 0.5849625007\n",
      "ig: 0.0 max_ig 0.5849625007\n",
      "ig: 0.0 max_ig 0.5849625007\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.4627552263 max_ig -1\n",
      "ig: 0.3060986114 max_ig 0.4627552263\n",
      "ig: 0.0 max_ig 0.4627552263\n",
      "ig: 0.0 max_ig 0.4627552263\n",
      "ig: 0.0 max_ig 0.4627552263\n",
      "ig: 0.0 max_ig 0.4627552263\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.5709505945 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.2916919971 max_ig -1\n",
      "ig: 0.6294817081 max_ig 0.2916919971\n",
      "ig: 0.0 max_ig 0.6294817081\n",
      "ig: 0.0 max_ig 0.6294817081\n",
      "ig: 0.0 max_ig 0.6294817081\n",
      "ig: 0.0 max_ig 0.6294817081\n",
      "ig: 0.1225562489 max_ig -1\n",
      "ig: 0.0 max_ig 0.1225562489\n",
      "ig: 0.0 max_ig 0.1225562489\n",
      "ig: 0.0 max_ig 0.1225562489\n",
      "ig: 0.0 max_ig 0.1225562489\n",
      "ig: 0.0 max_ig 0.1225562489\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 1.0 max_ig -1\n",
      "ig: 0.0 max_ig 1.0\n",
      "ig: 0.0 max_ig 1.0\n",
      "ig: 0.0 max_ig 1.0\n",
      "ig: 0.0 max_ig 1.0\n",
      "ig: 0.0 max_ig 1.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.2376084286 max_ig -1\n",
      "ig: 0.0977677275 max_ig 0.2376084286\n",
      "ig: 0.2129141018 max_ig 0.2376084286\n",
      "ig: 0.0 max_ig 0.2376084286\n",
      "ig: 0.0 max_ig 0.2376084286\n",
      "ig: 0.0 max_ig 0.2376084286\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.2349849224 max_ig 0.0\n",
      "ig: 0.1930467278 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.1180782093 max_ig 0.0\n",
      "ig: 0.3890282086 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.2998963912 max_ig 0.0\n",
      "ig: 0.1180782093 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.2160700717 max_ig -1\n",
      "ig: 0.1431660502 max_ig 0.2160700717\n",
      "ig: 0.0382091315 max_ig 0.2160700717\n",
      "ig: 0.0 max_ig 0.2160700717\n",
      "ig: 0.0 max_ig 0.2160700717\n",
      "ig: 0.0 max_ig 0.2160700717\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.3310385396 max_ig 0.0\n",
      "ig: 0.0453590568 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.5709505945 max_ig 0.0\n",
      "ig: 0.1709505945 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig -1\n",
      "ig: 0.4040097573 max_ig 0.0\n",
      "ig: 0.1180782093 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "ig: 0.0 max_ig 0.0\n",
      "branch 0{\n",
      "\tdeep: 0\n",
      "\tnum of samples for each class: 784 : 246 : 39 : 38 \n",
      "\tsplit by dim 5\n",
      "\tbranch 0->0{\n",
      "\t\tdeep: 1\n",
      "\t\tnum of samples for each class: 378 \n",
      "\t\tclass: 0\n",
      "\t}\n",
      "\tbranch 0->1{\n",
      "\t\tdeep: 1\n",
      "\t\tnum of samples for each class: 221 : 117 : 20 \n",
      "\t\tsplit by dim 3\n",
      "\t\tbranch 0->1->0{\n",
      "\t\t\tdeep: 2\n",
      "\t\t\tnum of samples for each class: 114 \n",
      "\t\t\tclass: 0\n",
      "\t\t}\n",
      "\t\tbranch 0->1->1{\n",
      "\t\t\tdeep: 2\n",
      "\t\t\tnum of samples for each class: 51 : 60 : 8 \n",
      "\t\t\tsplit by dim 4\n",
      "\t\t\tbranch 0->1->1->0{\n",
      "\t\t\t\tdeep: 3\n",
      "\t\t\t\tnum of samples for each class: 27 : 13 \n",
      "\t\t\t\tsplit by dim 0\n",
      "\t\t\t\tbranch 0->1->1->0->0{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 11 : 7 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->1->0->1{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 4 : 6 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->1->0->2{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 12 \n",
      "\t\t\t\t\tclass: 0\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tbranch 0->1->1->1{\n",
      "\t\t\t\tdeep: 3\n",
      "\t\t\t\tnum of samples for each class: 17 : 16 : 1 \n",
      "\t\t\t\tsplit by dim 2\n",
      "\t\t\t\tbranch 0->1->1->1->0{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 8 : 2 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\tbranch 0->1->1->1->0->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 4 : 2 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->1->1->0->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 1 \n",
      "\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->1->1->0->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 3 \n",
      "\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->1->1->1{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 6 : 2 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\tbranch 0->1->1->1->1->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 2 : 2 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->1->1->1->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 1 \n",
      "\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->1->1->1->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 3 \n",
      "\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->1->1->2{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 2 : 4 : 1 \n",
      "\t\t\t\t\tsplit by dim 1\n",
      "\t\t\t\t\tbranch 0->1->1->1->2->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 2 : 1 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\tbranch 0->1->1->1->2->0->0{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 1 : 1 \n",
      "\t\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tbranch 0->1->1->1->2->0->1{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 1 \n",
      "\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->1->1->2->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 : 2 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\tbranch 0->1->1->1->2->1->0{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 0 : 1 \n",
      "\t\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tbranch 0->1->1->1->2->1->1{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->1->1->2->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->1->1->3{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 1 : 8 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\tbranch 0->1->1->1->3->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 1 : 3 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->1->1->3->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->1->1->3->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tbranch 0->1->1->2{\n",
      "\t\t\t\tdeep: 3\n",
      "\t\t\t\tnum of samples for each class: 7 : 31 : 7 \n",
      "\t\t\t\tsplit by dim 0\n",
      "\t\t\t\tbranch 0->1->1->2->0{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 4 : 14 : 5 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->1->2->1{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 0 : 8 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->1->2->2{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 3 : 9 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tbranch 0->1->2{\n",
      "\t\t\tdeep: 2\n",
      "\t\t\tnum of samples for each class: 56 : 57 : 12 \n",
      "\t\t\tsplit by dim 4\n",
      "\t\t\tbranch 0->1->2->0{\n",
      "\t\t\t\tdeep: 3\n",
      "\t\t\t\tnum of samples for each class: 34 : 10 \n",
      "\t\t\t\tsplit by dim 0\n",
      "\t\t\t\tbranch 0->1->2->0->0{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 13 : 5 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->2->0->1{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 9 : 5 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->2->0->2{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 12 \n",
      "\t\t\t\t\tclass: 0\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tbranch 0->1->2->1{\n",
      "\t\t\t\tdeep: 3\n",
      "\t\t\t\tnum of samples for each class: 15 : 24 : 4 \n",
      "\t\t\t\tsplit by dim 2\n",
      "\t\t\t\tbranch 0->1->2->1->0{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 8 : 3 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\tbranch 0->1->2->1->0->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 3 : 2 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->1->0->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 2 : 1 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->1->0->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 3 \n",
      "\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->2->1->1{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 3 : 7 : 3 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\tbranch 0->1->2->1->1->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 2 : 3 : 2 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->1->1->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 : 2 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->1->1->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 1 : 2 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->2->1->2{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 3 : 7 \n",
      "\t\t\t\t\tsplit by dim 1\n",
      "\t\t\t\t\tbranch 0->1->2->1->2->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 2 : 3 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\tbranch 0->1->2->1->2->0->0{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 1 : 2 \n",
      "\t\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tbranch 0->1->2->1->2->0->1{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 1 : 1 \n",
      "\t\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->1->2->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->1->2->2{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 1 : 3 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\tbranch 0->1->2->1->2->2->0{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 1 : 1 \n",
      "\t\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tbranch 0->1->2->1->2->2->1{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tbranch 0->1->2->1->2->2->2{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->2->1->3{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 1 : 7 : 1 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\tbranch 0->1->2->1->3->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 1 : 3 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->1->3->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 : 1 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->1->3->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tbranch 0->1->2->2{\n",
      "\t\t\t\tdeep: 3\n",
      "\t\t\t\tnum of samples for each class: 7 : 23 : 8 \n",
      "\t\t\t\tsplit by dim 1\n",
      "\t\t\t\tbranch 0->1->2->2->0{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 4 : 11 : 4 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\tbranch 0->1->2->2->0->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 1 : 7 : 1 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->2->0->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 : 2 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->2->0->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 3 : 2 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->2->2->1{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 0 : 2 \n",
      "\t\t\t\t\tsplit by dim 2\n",
      "\t\t\t\t\tbranch 0->1->2->2->1->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 : 2 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\tbranch 0->1->2->2->1->0->0{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 0 : 1 \n",
      "\t\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tbranch 0->1->2->2->1->0->1{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->2->1->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 2\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->2->1->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 2\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->2->1->3{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 2\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->1->2->2->2{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 3 : 10 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\tbranch 0->1->2->2->2->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 3 : 3 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->2->2->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->1->2->2->2->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tbranch 0->2{\n",
      "\t\tdeep: 1\n",
      "\t\tnum of samples for each class: 185 : 129 : 19 : 38 \n",
      "\t\tsplit by dim 3\n",
      "\t\tbranch 0->2->0{\n",
      "\t\t\tdeep: 2\n",
      "\t\t\tnum of samples for each class: 133 \n",
      "\t\t\tclass: 0\n",
      "\t\t}\n",
      "\t\tbranch 0->2->1{\n",
      "\t\t\tdeep: 2\n",
      "\t\t\tnum of samples for each class: 21 : 66 : 13 : 18 \n",
      "\t\t\tsplit by dim 0\n",
      "\t\t\tbranch 0->2->1->0{\n",
      "\t\t\t\tdeep: 3\n",
      "\t\t\t\tnum of samples for each class: 13 : 29 : 9 : 9 \n",
      "\t\t\t\tsplit by dim 0\n",
      "\t\t\t}\n",
      "\t\t\tbranch 0->2->1->1{\n",
      "\t\t\t\tdeep: 3\n",
      "\t\t\t\tnum of samples for each class: 0 : 13 : 4 \n",
      "\t\t\t\tsplit by dim 0\n",
      "\t\t\t}\n",
      "\t\t\tbranch 0->2->1->2{\n",
      "\t\t\t\tdeep: 3\n",
      "\t\t\t\tnum of samples for each class: 8 : 24 \n",
      "\t\t\t\tsplit by dim 0\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tbranch 0->2->2{\n",
      "\t\t\tdeep: 2\n",
      "\t\t\tnum of samples for each class: 31 : 63 : 6 : 20 \n",
      "\t\t\tsplit by dim 4\n",
      "\t\t\tbranch 0->2->2->0{\n",
      "\t\t\t\tdeep: 3\n",
      "\t\t\t\tnum of samples for each class: 16 : 16 : 5 \n",
      "\t\t\t\tsplit by dim 2\n",
      "\t\t\t\tbranch 0->2->2->0->0{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 11 \n",
      "\t\t\t\t\tclass: 0\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->2->2->0->1{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 2 : 6 : 2 \n",
      "\t\t\t\t\tsplit by dim 1\n",
      "\t\t\t\t\tbranch 0->2->2->0->1->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 2 : 2 : 2 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\tbranch 0->2->2->0->1->0->0{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 1 : 0 \n",
      "\t\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tbranch 0->2->2->0->1->0->1{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 0 : 1 \n",
      "\t\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tbranch 0->2->2->0->1->0->2{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 1 : 1 \n",
      "\t\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->2->2->0->1->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->2->2->0->1->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->2->2->0->2{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 1 : 6 : 2 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\tbranch 0->2->2->0->2->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 1 : 3 : 1 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->2->2->0->2->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 2\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->2->2->0->2->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->2->2->0->3{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 2 : 4 : 1 \n",
      "\t\t\t\t\tsplit by dim 1\n",
      "\t\t\t\t\tbranch 0->2->2->0->3->0{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 1 : 3 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\tbranch 0->2->2->0->3->0->0{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 1 : 2 \n",
      "\t\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tbranch 0->2->2->0->3->0->1{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->2->2->0->3->1{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\tclass: 2\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbranch 0->2->2->0->3->2{\n",
      "\t\t\t\t\t\tdeep: 5\n",
      "\t\t\t\t\t\tnum of samples for each class: 1 : 1 \n",
      "\t\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t\t\tbranch 0->2->2->0->3->2->0{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 1 \n",
      "\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tbranch 0->2->2->0->3->2->1{\n",
      "\t\t\t\t\t\t\tdeep: 6\n",
      "\t\t\t\t\t\t\tnum of samples for each class: 0 \n",
      "\t\t\t\t\t\t\tclass: 1\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tbranch 0->2->2->1{\n",
      "\t\t\t\tdeep: 3\n",
      "\t\t\t\tnum of samples for each class: 7 : 24 : 1 : 8 \n",
      "\t\t\t\tsplit by dim 0\n",
      "\t\t\t\tbranch 0->2->2->1->0{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 4 : 10 : 0 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->2->2->1->1{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 0 : 6 : 1 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->2->2->1->2{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 3 : 8 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tbranch 0->2->2->2{\n",
      "\t\t\t\tdeep: 3\n",
      "\t\t\t\tnum of samples for each class: 8 : 23 : 0 \n",
      "\t\t\t\tsplit by dim 0\n",
      "\t\t\t\tbranch 0->2->2->2->0{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 5 : 9 : 0 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->2->2->2->1{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 0 : 6 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbranch 0->2->2->2->2{\n",
      "\t\t\t\t\tdeep: 4\n",
      "\t\t\t\t\tnum of samples for each class: 3 : 8 \n",
      "\t\t\t\t\tsplit by dim 0\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "import hw1_dt as decision_tree\n",
    "import utils as Utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features, labels = data.sample_decision_tree_data()\n",
    "\n",
    "# build the tree\n",
    "#features=[[1], [2], [1], [1]]\n",
    "#labels=[1,1,1,2]\n",
    "features=[[0, 2, 0, 0], [0, 2, 0, 1], [1, 0, 0, 0], [2, 1, 0, 0], [2, 2, 1, 0], [2, 2, 1, 1], [1, 2, 1, 1], [0, 1, 0, 0], [0, 2, 1, 0], [2, 1, 1, 0], [0, 1, 1, 1], [1, 1, 0, 1], [1, 0, 1, 0], [2, 1, 0, 1]]\n",
    "labels=[0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n",
    "#features=[['T', 'F', 'F', 'T', 'Some', '$$$', 'F', 'T', 'French', '0'], ['T', 'F', 'F', 'T', 'Full', '$', 'F', 'F', 'Thai', '30'], ['F', 'T', 'F', 'F', 'Some', '$', 'F', 'F', 'Burger', '0'], ['T', 'F', 'T', 'T', 'Full', '$', 'F', 'F', 'Thai', '10'], ['T', 'F', 'T', 'F', 'Full', '$$$', 'F', 'T', 'French', '60'], ['F', 'T', 'F', 'T', 'Some', '$$', 'T', 'T', 'Italian', '0'], ['F', 'T', 'F', 'F', 'None', '$', 'T', 'F', 'Burger', '0'], ['F', 'F', 'F', 'T', 'Some', '$$', 'T', 'T', 'Thai', '0'], ['F', 'T', 'T', 'F', 'Full', '$', 'T', 'F', 'Burger', '60'], ['T', 'T', 'T', 'T', 'Full', '$$$', 'F', 'T', 'Italian', '10'], ['F', 'F', 'F', 'F', 'None', '$', 'F', 'F', 'Thai', '0'], ['T', 'T', 'T', 'T', 'Full', '$', 'F', 'F', 'Burger', '30']]\n",
    "#labels=['T', 'F', 'T', 'T', 'F', 'T', 'F', 'T', 'F', 'F', 'F', 'T']\n",
    "#features=[['Sunny', 'High', 'Strong'], ['Sunny', 'Normal', 'Strong'], ['Overcast', 'High', 'Strong'], ['Overcast', 'Normal', 'Weak'], ['Overcast', 'High', 'Strong'], ['Overcast', 'Normal', 'Weak'], ['Overcast', 'High', 'Strong'], ['Overcast', 'Normal', 'Weak'], ['Rain', 'Normal', 'Strong'], ['Rain', 'Normal', 'Weak']] \n",
    "#labels=[0, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
    "#features=[[0, 0, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0], [2, 1, 0, 0], [2, 2, 1, 0], [2, 2, 1, 1], [1, 2, 1, 1], [0, 1, 0, 0], [0, 2, 1, 0], [2, 1, 1, 0], [0, 1, 1, 1], [1, 1, 0, 1], [1, 0, 1, 0], [2, 1, 0, 1]] \n",
    "#labels=[0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n",
    "\n",
    "#features=[[0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 0, 1], [0, 1, 0, 0], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 0, 1], [1, 0, 0, 0], [0, 1, 0, 0], [1, 1, 0, 0]] \n",
    "#labels=[1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "features=[[1, 0, 2, 2, 2, 1], [2, 2, 5, 2, 1, 2], [0, 0, 4, 5, 1, 1], [2, 0, 2, 4, 0, 0], [0, 0, 5, 5, 0, 2], [0, 2, 5, 5, 0, 0], [0, 0, 5, 2, 1, 2], [0, 1, 2, 4, 0, 2], [2, 0, 4, 4, 0, 0], [1, 2, 3, 4, 2, 0], [0, 0, 4, 2, 0, 1], [2, 0, 3, 5, 0, 2], [0, 1, 2, 4, 2, 0], [1, 2, 5, 5, 1, 0], [1, 1, 4, 2, 2, 0], [0, 0, 4, 2, 0, 1], [2, 2, 5, 4, 2, 2], [0, 1, 3, 4, 2, 1], [1, 0, 3, 5, 0, 0], [1, 0, 2, 2, 2, 0], [2, 0, 5, 5, 0, 2], [2, 2, 5, 4, 2, 0], [0, 2, 2, 2, 2, 2], [0, 1, 5, 5, 1, 2], [0, 0, 4, 2, 2, 2], [1, 1, 4, 4, 2, 1], [2, 2, 2, 5, 0, 2], [0, 0, 2, 2, 0, 2], [0, 2, 3, 5, 2, 2], [2, 0, 5, 4, 2, 0], [0, 2, 3, 2, 1, 1], [0, 1, 2, 4, 1, 1], [1, 2, 3, 5, 2, 2], [2, 2, 4, 2, 1, 0], [0, 0, 3, 2, 0, 0], [0, 1, 4, 4, 1, 0], [0, 0, 5, 5, 1, 2], [2, 0, 3, 2, 2, 0], [0, 0, 4, 2, 2, 0], [1, 1, 2, 5, 1, 2], [1, 1, 3, 5, 1, 1], [0, 0, 2, 2, 2, 0], [0, 0, 3, 5, 2, 2], [0, 1, 4, 4, 1, 0], [2, 0, 5, 4, 1, 1], [1, 0, 5, 5, 0, 1], [0, 0, 2, 5, 2, 1], [0, 2, 4, 2, 1, 1], [0, 1, 3, 2, 1, 2], [0, 0, 5, 5, 0, 0], [0, 0, 2, 4, 2, 1], [2, 1, 3, 2, 2, 2], [2, 0, 2, 2, 1, 1], [1, 2, 4, 2, 2, 0], [0, 0, 4, 2, 1, 2], [2, 0, 2, 5, 2, 1], [0, 1, 2, 4, 0, 2], [0, 0, 4, 2, 0, 1], [0, 2, 5, 4, 0, 1], [2, 0, 5, 2, 1, 1], [0, 0, 2, 5, 0, 1], [0, 0, 4, 5, 1, 2], [2, 0, 5, 5, 1, 1], [0, 0, 2, 4, 0, 1], [1, 0, 4, 4, 1, 2], [0, 0, 3, 5, 0, 2], [1, 0, 5, 2, 0, 0], [1, 2, 3, 2, 2, 2], [0, 1, 2, 5, 0, 0], [0, 0, 4, 4, 1, 1], [1, 0, 5, 4, 2, 0], [2, 0, 3, 5, 1, 1], [0, 0, 5, 5, 1, 0], [0, 0, 4, 5, 2, 2], [0, 0, 3, 2, 2, 2], [1, 1, 5, 2, 0, 2], [1, 0, 2, 4, 2, 1], [0, 0, 5, 4, 2, 1], [0, 1, 3, 5, 0, 0], [1, 0, 2, 4, 1, 0], [2, 0, 5, 2, 1, 2], [2, 2, 3, 5, 1, 0], [2, 0, 3, 5, 1, 1], [1, 0, 5, 5, 2, 1], [1, 0, 5, 2, 2, 2], [0, 0, 4, 2, 0, 2], [1, 0, 5, 5, 1, 0], [0, 1, 5, 4, 0, 2], [2, 0, 5, 2, 2, 1], [1, 0, 2, 2, 2, 2], [2, 0, 3, 4, 0, 1], [0, 0, 2, 5, 2, 1], [0, 2, 5, 4, 2, 1], [0, 1, 4, 4, 1, 1], [0, 0, 2, 2, 1, 0], [0, 2, 3, 2, 0, 2], [0, 0, 2, 5, 0, 1], [2, 0, 2, 5, 0, 0], [2, 2, 4, 4, 2, 1], [0, 0, 4, 2, 2, 0], [2, 0, 4, 5, 2, 0], [1, 0, 3, 2, 0, 1], [0, 0, 4, 2, 2, 2], [1, 0, 5, 5, 2, 0], [2, 1, 3, 4, 0, 2], [2, 0, 3, 4, 2, 1], [0, 0, 2, 4, 1, 2], [0, 1, 4, 2, 1, 2], [1, 2, 5, 5, 2, 0], [2, 0, 5, 4, 2, 1], [1, 2, 3, 2, 0, 1], [1, 2, 3, 5, 2, 1], [0, 2, 2, 2, 0, 2], [0, 0, 5, 5, 1, 0], [2, 1, 3, 2, 2, 0], [0, 0, 5, 5, 2, 0], [2, 0, 3, 5, 0, 0], [1, 2, 3, 5, 1, 0], [0, 0, 5, 5, 2, 1], [0, 0, 5, 2, 0, 1], [0, 0, 4, 5, 1, 0], [0, 1, 5, 5, 1, 0], [2, 1, 4, 2, 2, 1], [0, 0, 5, 4, 0, 1], [2, 2, 4, 2, 2, 1], [1, 2, 4, 5, 2, 2], [0, 0, 4, 4, 2, 1], [1, 1, 3, 4, 0, 0], [2, 1, 5, 5, 1, 2], [0, 2, 4, 5, 1, 2], [0, 2, 3, 5, 0, 1], [0, 0, 3, 4, 0, 2], [2, 2, 2, 4, 0, 1], [2, 0, 3, 5, 0, 1], [0, 0, 4, 4, 0, 2], [2, 1, 5, 5, 2, 0], [0, 0, 3, 2, 1, 1], [0, 2, 2, 5, 1, 1], [0, 0, 3, 5, 0, 1], [2, 0, 2, 5, 1, 2], [0, 2, 4, 5, 2, 0], [0, 0, 3, 5, 0, 0], [0, 1, 2, 2, 0, 2], [1, 2, 3, 5, 0, 0], [0, 0, 5, 4, 0, 0], [0, 2, 3, 2, 2, 0], [1, 0, 3, 4, 1, 0], [0, 1, 3, 5, 2, 0], [2, 1, 5, 4, 1, 1], [2, 1, 5, 2, 0, 2], [1, 0, 2, 2, 0, 1], [2, 0, 4, 2, 0, 0], [0, 0, 2, 4, 1, 2], [2, 0, 3, 2, 0, 1], [0, 1, 3, 4, 2, 1], [0, 2, 2, 4, 1, 2], [2, 1, 5, 5, 0, 1], [0, 1, 4, 4, 1, 1], [0, 2, 5, 5, 1, 0], [2, 1, 5, 2, 0, 1], [0, 0, 5, 4, 2, 0], [0, 0, 3, 5, 1, 0], [0, 1, 4, 2, 1, 1], [2, 0, 3, 4, 2, 2], [2, 2, 5, 5, 0, 2], [1, 0, 2, 2, 0, 1], [0, 0, 3, 5, 1, 2], [0, 1, 4, 4, 2, 2], [0, 0, 2, 2, 0, 0], [0, 0, 3, 2, 0, 1], [1, 2, 4, 5, 0, 1], [0, 2, 3, 2, 0, 2], [0, 1, 3, 2, 2, 2], [0, 0, 3, 5, 2, 0], [0, 2, 5, 5, 2, 1], [1, 0, 3, 5, 0, 2], [2, 2, 2, 2, 1, 0], [0, 1, 5, 5, 0, 2], [0, 0, 5, 4, 0, 2], [2, 1, 5, 4, 2, 1], [2, 0, 4, 2, 0, 0], [2, 2, 5, 4, 1, 1], [1, 0, 2, 5, 2, 1], [1, 0, 5, 4, 0, 2], [1, 0, 5, 4, 1, 2], [2, 1, 4, 2, 1, 1], [0, 2, 5, 2, 2, 0], [2, 2, 3, 2, 0, 2], [2, 0, 2, 2, 2, 1], [1, 0, 3, 5, 0, 1], [2, 1, 5, 2, 2, 1], [1, 2, 4, 5, 2, 0], [2, 2, 4, 4, 1, 0], [0, 0, 5, 4, 1, 2], [0, 1, 2, 2, 1, 0], [1, 0, 5, 4, 0, 1], [0, 2, 4, 2, 0, 0], [0, 1, 2, 4, 0, 1], [0, 2, 5, 5, 2, 0], [2, 2, 3, 2, 1, 1], [2, 2, 4, 4, 0, 0], [2, 1, 2, 2, 0, 2], [2, 1, 4, 5, 0, 1], [0, 0, 3, 5, 1, 1], [0, 2, 3, 2, 2, 1], [2, 2, 3, 2, 2, 0], [0, 1, 3, 4, 2, 2], [2, 2, 3, 4, 1, 2], [2, 0, 5, 4, 0, 0], [0, 1, 4, 5, 2, 1], [0, 0, 5, 2, 2, 0], [0, 2, 2, 5, 1, 0], [1, 0, 4, 5, 2, 0], [1, 2, 3, 4, 0, 0], [0, 0, 5, 5, 0, 1], [1, 0, 2, 4, 1, 0], [0, 0, 4, 5, 1, 1], [2, 1, 2, 5, 1, 1], [0, 1, 4, 5, 1, 1], [0, 2, 2, 2, 1, 1], [0, 1, 2, 4, 2, 2], [1, 0, 4, 5, 1, 0], [1, 1, 3, 4, 1, 0], [2, 0, 2, 5, 0, 1], [1, 1, 2, 5, 0, 2], [1, 0, 4, 2, 0, 2], [1, 0, 5, 4, 1, 2], [1, 0, 4, 5, 1, 2], [1, 0, 2, 4, 2, 2], [2, 1, 5, 5, 1, 0], [0, 1, 5, 4, 1, 0], [2, 0, 4, 2, 1, 1], [2, 0, 3, 4, 1, 0], [0, 0, 5, 2, 0, 1], [0, 0, 5, 4, 2, 0], [0, 1, 3, 4, 1, 0], [0, 2, 3, 4, 1, 1], [1, 2, 5, 4, 1, 0], [0, 2, 5, 2, 2, 2], [1, 0, 2, 2, 0, 0], [0, 1, 5, 5, 0, 1], [2, 0, 3, 5, 1, 0], [2, 0, 3, 5, 1, 2], [1, 0, 3, 5, 1, 2], [2, 0, 3, 4, 2, 0], [0, 0, 5, 4, 2, 2], [1, 2, 5, 4, 0, 0], [0, 0, 5, 2, 0, 0], [2, 0, 4, 5, 0, 2], [0, 2, 5, 4, 1, 0], [1, 1, 5, 2, 2, 2], [2, 1, 3, 2, 0, 0], [2, 0, 4, 2, 2, 1], [1, 0, 2, 2, 1, 2], [2, 2, 2, 2, 0, 2], [2, 2, 2, 4, 1, 2], [0, 2, 3, 2, 0, 0], [2, 1, 4, 4, 1, 1], [0, 2, 2, 5, 0, 1], [2, 0, 2, 4, 1, 1], [0, 2, 2, 4, 2, 2], [0, 0, 3, 5, 0, 1], [2, 1, 4, 2, 0, 2], [0, 0, 2, 5, 2, 2], [1, 1, 3, 4, 2, 2], [0, 1, 2, 4, 1, 2], [0, 0, 3, 2, 1, 1], [0, 0, 2, 5, 1, 1], [2, 0, 2, 2, 1, 2], [0, 2, 5, 4, 2, 2], [0, 0, 5, 2, 1, 0], [0, 0, 2, 4, 2, 2], [1, 2, 2, 2, 0, 1], [0, 1, 3, 2, 0, 2], [2, 1, 3, 4, 0, 0], [2, 2, 5, 2, 0, 1], [2, 1, 5, 2, 0, 0], [0, 0, 2, 4, 0, 2], [1, 1, 2, 2, 1, 0], [1, 1, 5, 2, 0, 0], [0, 1, 3, 4, 1, 0], [1, 2, 3, 5, 2, 0], [0, 2, 3, 5, 1, 0], [0, 0, 4, 5, 0, 0], [0, 0, 5, 4, 2, 2], [1, 1, 4, 2, 0, 2], [0, 0, 4, 2, 1, 1], [0, 0, 4, 4, 0, 1], [1, 0, 3, 2, 0, 0], [0, 0, 5, 4, 1, 0], [0, 1, 4, 2, 0, 0], [0, 2, 4, 5, 0, 2], [0, 0, 2, 4, 0, 0], [0, 0, 2, 4, 1, 1], [1, 0, 5, 5, 1, 1], [0, 2, 5, 2, 0, 2], [2, 0, 4, 2, 0, 2], [2, 1, 2, 2, 1, 1], [1, 0, 3, 2, 1, 1], [1, 1, 3, 5, 2, 0], [0, 0, 2, 4, 2, 0], [0, 2, 4, 5, 0, 0], [2, 2, 2, 5, 0, 1], [1, 0, 5, 5, 1, 2], [0, 0, 2, 5, 0, 2], [0, 0, 4, 5, 1, 0], [1, 1, 2, 4, 2, 1], [0, 2, 2, 2, 0, 0], [0, 1, 2, 5, 0, 2], [2, 2, 5, 5, 1, 0], [2, 2, 2, 4, 1, 0], [2, 1, 3, 4, 1, 0], [0, 0, 2, 5, 1, 0], [2, 0, 2, 2, 1, 0], [0, 2, 3, 4, 0, 2], [2, 1, 4, 4, 0, 0], [0, 2, 3, 4, 0, 1], [1, 2, 2, 4, 1, 1], [0, 2, 5, 2, 1, 1], [2, 2, 5, 2, 2, 2], [1, 1, 5, 5, 2, 0], [1, 0, 3, 5, 1, 2], [2, 0, 3, 4, 0, 1], [0, 1, 3, 5, 2, 1], [2, 2, 4, 2, 0, 2], [2, 0, 4, 4, 2, 2], [1, 0, 3, 2, 2, 0], [0, 0, 5, 2, 2, 0], [2, 1, 2, 2, 2, 2], [0, 0, 3, 2, 2, 0], [2, 2, 5, 5, 2, 1], [0, 0, 3, 5, 1, 0], [1, 0, 2, 2, 1, 1], [1, 2, 2, 2, 1, 0], [2, 0, 4, 5, 1, 1], [0, 1, 3, 2, 0, 2], [0, 2, 4, 5, 1, 2], [0, 2, 3, 5, 1, 0], [0, 2, 2, 4, 0, 1], [0, 0, 2, 5, 2, 2], [0, 2, 5, 5, 2, 0], [0, 0, 3, 2, 1, 1], [0, 0, 3, 5, 1, 0], [0, 2, 5, 2, 2, 2], [1, 0, 3, 5, 2, 0], [2, 2, 3, 2, 2, 1], [1, 2, 4, 4, 0, 0], [0, 0, 2, 2, 1, 2], [0, 1, 4, 4, 2, 0], [2, 0, 4, 2, 0, 2], [2, 0, 3, 4, 1, 2], [0, 2, 4, 4, 2, 1], [2, 2, 4, 5, 1, 1], [0, 1, 3, 4, 0, 2], [0, 2, 4, 4, 2, 2], [0, 1, 3, 5, 0, 0], [1, 1, 5, 2, 2, 1], [0, 2, 4, 2, 2, 0], [1, 2, 5, 5, 0, 0], [2, 0, 4, 4, 1, 0], [1, 0, 5, 4, 2, 2], [0, 0, 3, 2, 0, 2], [1, 2, 3, 2, 2, 0], [1, 0, 2, 4, 1, 2], [0, 0, 2, 2, 2, 0], [2, 1, 2, 4, 1, 1], [0, 1, 2, 4, 2, 0], [0, 1, 5, 2, 1, 2], [0, 0, 2, 2, 1, 1], [1, 0, 2, 5, 0, 0], [2, 1, 5, 2, 1, 1], [2, 0, 2, 4, 1, 1], [0, 0, 2, 4, 1, 1], [0, 0, 3, 4, 2, 1], [1, 0, 2, 5, 2, 2], [0, 0, 3, 2, 2, 2], [2, 0, 2, 2, 0, 1], [2, 2, 3, 5, 2, 2], [2, 0, 2, 4, 0, 2], [2, 0, 3, 5, 2, 1], [0, 2, 4, 4, 0, 1], [2, 0, 2, 5, 2, 2], [1, 0, 3, 2, 2, 1], [0, 2, 4, 2, 1, 2], [2, 2, 4, 5, 1, 0], [0, 2, 5, 5, 1, 1], [0, 1, 3, 2, 2, 2], [2, 0, 5, 4, 2, 0], [0, 2, 3, 2, 1, 0], [2, 0, 2, 4, 2, 0], [0, 0, 4, 5, 1, 2], [1, 2, 4, 5, 1, 2], [1, 0, 2, 5, 1, 1], [2, 0, 3, 4, 2, 2], [0, 0, 5, 2, 2, 1], [1, 1, 5, 4, 0, 2], [2, 1, 2, 4, 0, 0], [0, 1, 4, 5, 2, 0], [2, 0, 5, 2, 0, 2], [0, 0, 2, 5, 0, 0], [0, 0, 5, 4, 0, 1], [2, 0, 4, 5, 1, 0], [1, 0, 3, 4, 0, 0], [1, 0, 5, 2, 1, 2], [0, 0, 3, 2, 2, 1], [0, 1, 3, 4, 1, 1], [0, 0, 4, 4, 1, 1], [0, 2, 2, 2, 1, 2], [0, 2, 4, 5, 2, 1], [0, 0, 2, 2, 1, 0], [2, 2, 5, 2, 2, 1], [1, 1, 5, 5, 1, 0], [2, 0, 5, 4, 0, 1], [2, 2, 3, 2, 2, 2], [1, 2, 3, 2, 1, 2], [1, 0, 5, 2, 2, 1], [1, 0, 4, 4, 1, 0], [0, 2, 4, 5, 0, 1], [2, 2, 2, 2, 0, 0], [0, 2, 3, 2, 2, 2], [0, 0, 5, 5, 0, 1], [1, 2, 4, 2, 0, 1], [0, 0, 2, 4, 1, 1], [0, 2, 3, 4, 2, 2], [0, 1, 3, 5, 0, 2], [2, 2, 4, 4, 0, 2], [0, 0, 3, 4, 0, 2], [2, 0, 5, 4, 2, 1], [2, 2, 2, 2, 1, 2], [0, 1, 2, 5, 2, 0], [2, 1, 2, 5, 2, 2], [0, 0, 5, 2, 0, 0], [0, 2, 2, 2, 1, 0], [0, 2, 4, 4, 0, 2], [0, 0, 4, 5, 2, 2], [1, 2, 2, 5, 2, 1], [0, 2, 4, 4, 1, 0], [2, 1, 4, 2, 2, 2], [1, 1, 3, 5, 2, 2], [1, 0, 3, 5, 1, 1], [0, 1, 3, 2, 1, 1], [0, 2, 3, 5, 0, 1], [0, 2, 5, 5, 2, 1], [0, 1, 3, 2, 1, 1], [0, 2, 4, 4, 2, 0], [1, 1, 3, 4, 2, 1], [1, 0, 3, 2, 2, 1], [2, 1, 3, 2, 1, 1], [0, 1, 2, 5, 0, 1], [2, 0, 3, 2, 2, 0], [2, 2, 4, 5, 2, 2], [2, 0, 3, 2, 2, 2], [0, 0, 3, 2, 1, 0], [0, 2, 2, 2, 2, 2], [0, 1, 3, 2, 0, 1], [0, 1, 2, 4, 1, 2], [2, 1, 3, 4, 1, 1], [2, 0, 5, 4, 0, 2], [2, 2, 2, 4, 2, 2], [0, 0, 3, 4, 1, 0], [1, 0, 3, 2, 1, 0], [0, 2, 3, 4, 2, 2], [1, 0, 4, 4, 2, 1], [0, 0, 5, 4, 1, 1], [0, 0, 3, 5, 0, 0], [0, 0, 5, 2, 2, 1], [1, 0, 2, 4, 0, 1], [2, 1, 2, 5, 0, 0], [0, 1, 2, 2, 0, 1], [0, 2, 3, 2, 2, 2], [1, 1, 2, 2, 1, 1], [0, 1, 4, 5, 1, 2], [0, 1, 4, 5, 0, 0], [0, 0, 3, 4, 2, 0], [1, 0, 5, 2, 2, 0], [1, 0, 4, 2, 2, 2], [1, 1, 5, 5, 0, 1], [1, 0, 5, 5, 0, 1], [2, 0, 4, 2, 1, 0], [2, 1, 3, 5, 2, 0], [2, 0, 3, 2, 1, 2], [0, 0, 5, 4, 0, 0], [2, 0, 4, 2, 1, 0], [2, 1, 2, 4, 2, 2], [0, 0, 2, 4, 1, 0], [1, 2, 5, 2, 1, 0], [2, 2, 5, 5, 0, 0], [0, 1, 5, 4, 1, 2], [1, 2, 5, 2, 2, 1], [1, 0, 5, 5, 1, 0], [2, 2, 5, 5, 0, 1], [2, 0, 2, 2, 2, 0], [0, 0, 3, 2, 1, 2], [0, 0, 3, 5, 1, 2], [0, 1, 5, 5, 0, 1], [0, 1, 2, 2, 0, 0], [2, 2, 4, 2, 0, 0], [1, 1, 4, 5, 0, 0], [1, 2, 2, 2, 0, 0], [2, 0, 2, 5, 0, 0], [2, 1, 4, 2, 2, 0], [2, 1, 5, 4, 1, 0], [2, 0, 4, 4, 2, 1], [0, 0, 3, 5, 1, 1], [2, 2, 5, 5, 1, 1], [0, 2, 4, 4, 1, 1], [0, 2, 2, 4, 0, 2], [0, 2, 5, 4, 0, 0], [0, 0, 2, 5, 0, 0], [0, 2, 3, 2, 1, 1], [0, 0, 4, 4, 2, 1], [0, 0, 3, 2, 0, 0], [0, 2, 4, 5, 1, 0], [1, 0, 5, 2, 1, 0], [0, 1, 3, 2, 0, 1], [0, 0, 2, 5, 1, 2], [1, 1, 5, 5, 1, 1], [0, 0, 5, 2, 1, 0], [0, 2, 5, 4, 0, 2], [0, 0, 4, 5, 2, 1], [2, 0, 4, 5, 2, 1], [1, 1, 4, 4, 2, 2], [0, 1, 3, 5, 1, 0], [0, 0, 2, 5, 2, 0], [0, 1, 4, 4, 2, 0], [0, 2, 3, 2, 0, 0], [0, 0, 4, 2, 1, 0], [0, 0, 4, 2, 1, 0], [2, 0, 4, 2, 2, 2], [2, 2, 4, 4, 2, 0], [0, 0, 3, 4, 2, 1], [2, 0, 2, 5, 1, 0], [0, 2, 5, 2, 1, 1], [0, 1, 2, 5, 1, 2], [1, 0, 5, 5, 2, 1], [2, 1, 2, 4, 1, 2], [1, 2, 3, 2, 1, 1], [0, 2, 4, 2, 2, 2], [2, 2, 2, 2, 2, 2], [2, 0, 2, 5, 1, 0], [2, 1, 4, 4, 2, 0], [0, 1, 5, 2, 2, 1], [0, 2, 5, 4, 1, 0], [1, 0, 5, 2, 1, 1], [2, 0, 2, 5, 1, 2], [0, 1, 4, 5, 0, 2], [0, 1, 2, 5, 2, 1], [0, 1, 3, 2, 2, 0], [1, 2, 5, 5, 2, 2], [1, 1, 3, 2, 0, 1], [0, 0, 2, 4, 0, 0], [0, 0, 2, 2, 2, 2], [0, 1, 2, 2, 0, 0], [1, 1, 5, 5, 2, 2], [1, 0, 2, 5, 0, 1], [0, 1, 5, 4, 1, 0], [2, 2, 5, 5, 2, 0], [2, 0, 4, 4, 1, 1], [2, 0, 2, 4, 2, 0], [2, 1, 5, 2, 2, 2], [0, 0, 3, 2, 0, 1], [1, 0, 4, 5, 0, 0], [0, 2, 4, 2, 1, 0], [0, 1, 5, 5, 1, 0], [0, 2, 4, 4, 1, 0], [0, 2, 4, 4, 2, 2], [0, 0, 5, 4, 1, 1], [1, 0, 3, 4, 0, 2], [1, 1, 5, 4, 2, 1], [0, 0, 4, 2, 0, 2], [2, 0, 5, 4, 0, 2], [2, 0, 4, 2, 2, 0], [1, 1, 5, 4, 1, 1], [1, 2, 3, 2, 0, 0], [1, 1, 2, 2, 0, 2], [2, 0, 2, 4, 2, 1], [1, 2, 4, 5, 1, 1], [0, 2, 3, 5, 1, 1], [1, 0, 2, 2, 0, 2], [1, 0, 3, 4, 0, 1], [1, 0, 2, 2, 0, 0], [1, 1, 5, 4, 0, 1], [0, 1, 4, 4, 2, 1], [2, 1, 4, 5, 1, 2], [2, 1, 3, 5, 1, 0], [0, 0, 4, 2, 0, 2], [0, 2, 3, 5, 2, 0], [0, 0, 3, 5, 0, 2], [1, 1, 3, 5, 0, 0], [1, 0, 4, 5, 0, 1], [1, 0, 4, 5, 1, 2], [0, 0, 3, 4, 1, 1], [2, 2, 3, 4, 1, 0], [0, 0, 2, 5, 0, 2], [0, 0, 3, 5, 2, 1], [2, 0, 5, 2, 1, 0], [0, 0, 4, 5, 2, 0], [1, 0, 5, 2, 2, 2], [2, 0, 5, 5, 2, 0], [0, 1, 4, 5, 2, 0], [1, 0, 5, 2, 2, 1], [0, 1, 5, 5, 2, 0], [0, 2, 4, 2, 0, 2], [0, 1, 4, 2, 2, 2], [2, 2, 4, 4, 2, 2], [1, 0, 2, 2, 1, 2], [2, 0, 3, 2, 0, 0], [2, 0, 3, 5, 2, 2], [2, 2, 5, 2, 1, 0], [0, 1, 2, 5, 2, 1], [1, 0, 5, 5, 2, 0], [1, 0, 3, 4, 2, 1], [2, 1, 4, 5, 1, 0], [1, 0, 3, 2, 1, 2], [1, 2, 5, 4, 2, 0], [1, 0, 3, 4, 2, 0], [2, 0, 3, 2, 1, 0], [2, 2, 4, 5, 0, 2], [1, 2, 4, 4, 1, 2], [0, 0, 4, 4, 1, 0], [2, 2, 3, 2, 1, 2], [0, 0, 5, 5, 1, 2], [2, 1, 2, 5, 0, 2], [2, 0, 2, 5, 2, 2], [2, 0, 4, 4, 1, 2], [0, 2, 4, 4, 0, 0], [0, 2, 4, 5, 0, 0], [0, 0, 4, 4, 1, 2], [0, 2, 3, 2, 2, 1], [0, 0, 5, 4, 2, 1], [0, 2, 3, 5, 2, 1], [0, 1, 4, 2, 1, 2], [1, 0, 2, 5, 0, 2], [0, 0, 3, 2, 1, 2], [0, 2, 5, 4, 2, 0], [0, 0, 5, 5, 2, 2], [1, 2, 2, 5, 1, 1], [2, 1, 2, 5, 0, 1], [1, 2, 2, 5, 2, 2], [1, 2, 2, 5, 2, 0], [0, 0, 3, 4, 0, 0], [2, 1, 5, 4, 2, 0], [2, 0, 2, 5, 1, 1], [0, 2, 2, 4, 0, 2], [2, 2, 2, 5, 1, 2], [0, 1, 4, 5, 2, 2], [0, 0, 4, 4, 1, 0], [2, 1, 5, 5, 1, 1], [0, 2, 4, 5, 2, 2], [0, 1, 2, 2, 2, 2], [0, 0, 3, 2, 2, 1], [1, 0, 4, 2, 1, 2], [2, 0, 5, 5, 2, 1], [1, 0, 2, 4, 2, 0], [0, 1, 4, 4, 2, 2], [1, 0, 3, 5, 2, 2], [0, 0, 4, 5, 2, 0], [0, 2, 2, 5, 1, 0], [2, 0, 3, 2, 0, 2], [1, 0, 3, 2, 0, 1], [2, 0, 2, 4, 2, 2], [0, 0, 3, 2, 2, 0], [1, 2, 4, 2, 0, 0], [1, 0, 2, 2, 2, 0], [1, 0, 3, 4, 0, 2], [0, 0, 3, 5, 2, 2], [2, 1, 4, 4, 1, 2], [0, 1, 4, 2, 2, 0], [0, 0, 2, 4, 2, 1], [0, 0, 5, 2, 0, 2], [2, 1, 2, 5, 1, 0], [2, 2, 4, 4, 0, 1], [0, 0, 3, 2, 0, 2], [1, 0, 2, 2, 0, 2], [1, 0, 4, 2, 1, 2], [0, 0, 2, 4, 0, 0], [2, 0, 2, 5, 0, 2], [1, 2, 5, 5, 2, 1], [0, 0, 2, 2, 1, 2], [0, 0, 2, 5, 0, 2], [2, 2, 4, 5, 2, 1], [0, 2, 4, 5, 0, 2], [2, 0, 2, 5, 2, 0], [0, 1, 3, 5, 2, 2], [2, 0, 3, 2, 0, 1], [0, 0, 4, 2, 1, 2], [0, 1, 2, 4, 1, 0], [0, 1, 5, 5, 1, 1], [0, 1, 5, 5, 0, 0], [0, 0, 2, 5, 1, 2], [1, 1, 4, 4, 0, 0], [2, 0, 3, 5, 0, 1], [0, 0, 2, 5, 1, 0], [0, 0, 3, 4, 0, 1], [0, 2, 4, 2, 2, 0], [0, 2, 3, 4, 1, 2], [1, 1, 4, 2, 1, 1], [2, 1, 2, 2, 0, 0], [0, 0, 2, 5, 2, 2], [0, 1, 4, 5, 1, 0], [2, 0, 2, 4, 0, 2], [0, 2, 2, 5, 0, 0], [0, 0, 3, 5, 1, 1], [0, 2, 2, 5, 1, 2], [0, 0, 2, 4, 2, 0], [1, 0, 3, 5, 2, 1], [0, 2, 4, 2, 0, 2], [0, 0, 2, 4, 0, 2], [2, 2, 3, 4, 2, 0], [0, 2, 2, 5, 2, 0], [0, 0, 4, 4, 1, 2], [0, 2, 5, 5, 2, 2], [1, 0, 5, 2, 1, 2], [2, 2, 5, 4, 1, 0], [0, 0, 2, 4, 0, 1], [2, 0, 4, 2, 1, 1], [0, 2, 2, 2, 2, 0], [0, 2, 2, 4, 0, 0], [0, 2, 5, 5, 0, 2], [0, 2, 5, 4, 1, 2], [1, 2, 3, 4, 2, 1], [0, 1, 2, 2, 1, 1], [2, 0, 5, 2, 0, 0], [2, 0, 2, 2, 2, 2], [2, 1, 2, 2, 2, 0], [2, 2, 4, 2, 2, 2], [2, 0, 4, 5, 1, 1], [0, 0, 4, 2, 2, 1], [0, 2, 3, 2, 1, 2], [0, 0, 2, 2, 1, 2], [1, 2, 4, 2, 1, 0], [1, 1, 3, 2, 1, 0], [2, 0, 5, 2, 2, 2], [1, 0, 3, 2, 2, 0], [0, 0, 5, 5, 0, 1], [1, 1, 2, 4, 2, 2], [0, 2, 2, 2, 1, 2], [2, 0, 5, 4, 0, 1], [2, 0, 4, 5, 1, 2], [1, 1, 3, 2, 2, 0], [0, 0, 3, 5, 0, 0], [0, 0, 5, 2, 0, 2], [1, 0, 5, 2, 1, 1], [0, 0, 2, 4, 2, 0], [1, 0, 4, 5, 0, 1], [2, 0, 2, 4, 2, 1], [0, 0, 5, 4, 1, 0], [2, 0, 5, 4, 1, 2], [2, 0, 4, 4, 0, 1], [1, 2, 5, 2, 0, 1], [1, 0, 3, 4, 0, 1], [0, 0, 4, 4, 0, 0], [0, 1, 3, 4, 1, 1], [2, 1, 2, 4, 0, 2], [2, 1, 3, 2, 1, 0], [0, 0, 3, 4, 1, 2], [0, 1, 4, 2, 2, 2], [0, 0, 2, 5, 1, 0], [1, 1, 4, 5, 2, 0], [1, 1, 2, 2, 1, 2], [0, 0, 3, 4, 0, 0], [0, 1, 4, 5, 0, 2], [0, 2, 3, 2, 1, 2], [0, 0, 5, 5, 1, 1], [0, 1, 4, 2, 0, 2], [1, 0, 3, 5, 2, 0], [1, 2, 5, 4, 0, 1], [2, 0, 4, 2, 1, 2], [0, 2, 5, 5, 1, 1], [0, 2, 3, 5, 0, 0], [0, 2, 4, 5, 1, 0], [0, 2, 3, 2, 0, 1], [2, 2, 4, 2, 2, 0], [2, 0, 5, 5, 0, 1], [1, 2, 3, 2, 0, 2], [0, 1, 5, 5, 2, 2], [2, 2, 2, 5, 0, 0], [2, 2, 4, 2, 1, 2], [0, 1, 4, 4, 0, 1], [2, 0, 4, 5, 0, 1], [2, 0, 3, 5, 0, 2], [0, 2, 4, 2, 1, 2], [0, 0, 3, 4, 2, 0], [2, 2, 4, 5, 1, 2], [0, 1, 5, 4, 0, 1], [2, 1, 4, 5, 2, 0], [0, 2, 5, 2, 0, 0], [1, 1, 3, 5, 0, 1], [0, 0, 5, 5, 2, 2], [1, 0, 2, 5, 0, 1], [1, 1, 5, 4, 1, 0], [0, 1, 2, 5, 2, 2], [0, 0, 4, 5, 0, 2], [0, 0, 2, 4, 2, 1], [2, 0, 3, 4, 1, 0], [0, 0, 5, 2, 2, 2], [0, 1, 5, 4, 0, 0], [0, 0, 3, 5, 2, 0], [2, 0, 4, 4, 2, 2], [1, 0, 3, 5, 1, 0], [1, 2, 4, 4, 0, 1], [1, 0, 4, 2, 1, 0], [2, 0, 5, 2, 0, 2], [0, 0, 3, 5, 0, 0], [2, 0, 3, 2, 1, 2], [2, 0, 3, 2, 1, 0], [0, 2, 5, 2, 1, 2], [2, 0, 4, 5, 1, 2], [2, 0, 2, 4, 0, 1], [2, 0, 5, 2, 1, 0], [0, 2, 5, 5, 1, 0], [0, 1, 2, 2, 0, 1], [0, 0, 2, 5, 2, 0], [2, 0, 2, 2, 0, 2], [2, 0, 5, 4, 2, 2], [1, 0, 4, 5, 0, 2], [0, 1, 4, 4, 0, 0], [0, 0, 3, 5, 0, 1], [1, 0, 5, 4, 0, 0], [0, 1, 3, 5, 1, 1], [2, 1, 4, 2, 0, 1], [1, 0, 2, 5, 1, 1], [1, 1, 5, 2, 1, 1], [0, 2, 2, 4, 1, 0], [0, 1, 5, 5, 2, 2], [0, 2, 5, 2, 0, 2], [0, 0, 2, 4, 2, 2], [0, 1, 5, 4, 2, 1], [0, 2, 3, 5, 1, 1], [1, 0, 3, 2, 0, 2], [0, 1, 5, 2, 2, 0], [1, 0, 2, 4, 0, 0], [1, 0, 2, 2, 1, 1], [0, 2, 4, 4, 2, 0], [2, 1, 4, 5, 0, 2], [2, 0, 2, 5, 0, 1], [1, 0, 4, 4, 0, 2], [0, 0, 2, 5, 1, 1], [0, 2, 2, 5, 0, 2], [2, 2, 5, 4, 0, 2], [0, 1, 5, 2, 0, 0], [0, 0, 2, 4, 2, 2], [1, 0, 5, 5, 1, 2], [1, 0, 4, 4, 2, 2], [2, 1, 3, 4, 2, 1], [0, 0, 2, 4, 0, 1], [0, 1, 3, 4, 1, 2], [2, 1, 2, 2, 1, 2], [2, 0, 3, 4, 0, 2], [0, 1, 5, 2, 1, 0], [0, 2, 3, 4, 1, 2], [1, 2, 5, 2, 0, 0], [1, 0, 4, 2, 1, 1], [2, 1, 3, 2, 0, 2], [0, 0, 5, 5, 2, 1], [0, 0, 4, 5, 0, 0], [2, 2, 2, 4, 2, 1], [0, 1, 5, 2, 0, 1], [0, 0, 5, 5, 0, 2], [0, 1, 5, 4, 0, 2], [0, 1, 2, 5, 1, 0], [0, 0, 3, 2, 1, 0], [2, 2, 4, 2, 1, 1], [0, 2, 3, 4, 0, 0], [2, 1, 2, 2, 2, 1], [1, 2, 4, 2, 2, 1], [2, 0, 2, 4, 1, 0], [0, 2, 4, 5, 1, 1], [0, 1, 2, 5, 1, 1], [0, 1, 4, 4, 1, 2], [0, 0, 3, 2, 2, 1], [0, 0, 3, 2, 2, 0], [0, 1, 3, 2, 0, 0], [1, 2, 4, 4, 2, 1], [0, 0, 4, 2, 0, 2], [2, 2, 2, 5, 2, 2], [0, 2, 2, 4, 2, 0], [1, 0, 5, 2, 0, 2], [2, 1, 3, 5, 0, 2], [2, 2, 3, 4, 1, 1], [0, 0, 4, 4, 2, 2], [1, 0, 2, 5, 1, 2], [0, 2, 5, 5, 1, 2], [1, 0, 5, 4, 1, 0], [1, 1, 4, 2, 0, 0], [0, 2, 5, 2, 1, 0], [2, 0, 3, 5, 2, 1], [1, 2, 2, 4, 0, 2], [2, 1, 5, 4, 0, 0], [1, 0, 4, 5, 2, 2], [1, 0, 3, 2, 1, 1], [0, 0, 5, 4, 0, 0], [0, 1, 3, 5, 2, 0], [0, 2, 4, 5, 1, 1], [0, 0, 5, 5, 0, 2], [0, 1, 5, 4, 0, 1], [1, 0, 5, 4, 2, 1], [0, 2, 5, 4, 1, 1], [2, 2, 3, 5, 0, 2], [0, 2, 5, 5, 0, 1], [2, 1, 4, 4, 0, 1], [0, 0, 4, 2, 1, 0], [2, 0, 4, 5, 0, 1], [0, 0, 3, 4, 1, 2], [0, 0, 2, 4, 1, 1], [0, 2, 2, 5, 0, 0], [0, 2, 5, 2, 2, 1], [2, 1, 3, 5, 2, 2], [1, 1, 3, 2, 1, 1], [0, 0, 3, 4, 0, 1], [0, 2, 5, 5, 0, 1], [0, 2, 4, 4, 2, 1], [0, 0, 2, 5, 2, 0], [0, 0, 2, 5, 0, 0], [2, 0, 5, 5, 0, 0], [1, 0, 3, 4, 1, 2], [2, 0, 5, 5, 1, 2], [2, 0, 3, 2, 2, 1], [0, 0, 4, 5, 0, 1], [2, 1, 2, 4, 1, 0], [1, 0, 3, 4, 2, 2], [1, 0, 4, 2, 0, 0], [0, 1, 4, 4, 2, 1], [2, 2, 4, 5, 2, 0], [1, 0, 2, 5, 0, 0], [0, 2, 3, 4, 2, 0], [0, 0, 5, 2, 2, 2], [1, 0, 4, 4, 0, 1], [0, 1, 4, 2, 0, 1], [1, 1, 2, 4, 0, 2], [0, 0, 2, 5, 1, 1], [0, 1, 5, 4, 2, 1], [1, 2, 5, 4, 2, 2], [0, 1, 4, 5, 1, 2], [1, 0, 3, 5, 1, 0], [0, 1, 4, 2, 1, 1], [0, 2, 5, 4, 2, 1], [1, 1, 3, 4, 0, 2], [1, 1, 5, 4, 0, 0], [1, 1, 3, 5, 0, 2], [0, 1, 2, 2, 2, 0], [0, 2, 3, 5, 2, 2], [1, 2, 4, 4, 1, 0], [0, 2, 4, 5, 2, 1], [0, 0, 3, 4, 2, 2], [2, 1, 5, 4, 1, 2], [1, 2, 3, 4, 1, 2], [0, 0, 4, 4, 2, 2], [0, 0, 3, 4, 1, 2], [0, 0, 4, 5, 2, 1], [0, 1, 5, 2, 2, 2], [2, 0, 3, 4, 0, 0], [0, 0, 4, 2, 2, 1], [1, 0, 4, 2, 0, 0], [0, 0, 3, 4, 1, 2], [2, 2, 3, 5, 1, 2], [0, 0, 5, 4, 1, 1], [0, 0, 2, 5, 0, 0], [0, 0, 4, 2, 1, 2], [2, 2, 5, 4, 1, 2], [0, 1, 5, 2, 0, 2], [1, 2, 5, 5, 0, 1], [0, 1, 2, 2, 2, 2], [2, 0, 5, 5, 2, 0], [0, 0, 4, 2, 2, 2], [1, 0, 3, 5, 1, 1], [2, 1, 5, 5, 2, 2], [2, 0, 4, 5, 0, 0], [0, 2, 2, 2, 1, 1], [1, 0, 5, 4, 1, 1], [1, 2, 3, 5, 0, 1], [0, 0, 5, 4, 0, 2], [1, 0, 5, 5, 0, 0], [2, 0, 4, 2, 0, 1], [0, 1, 2, 2, 1, 2], [0, 2, 2, 4, 2, 0], [2, 0, 2, 2, 1, 0], [0, 1, 5, 4, 1, 2], [0, 1, 3, 5, 2, 2], [1, 0, 3, 2, 0, 2], [0, 2, 2, 4, 0, 0], [1, 2, 2, 2, 1, 1], [1, 0, 2, 4, 0, 2], [1, 2, 2, 5, 0, 2], [0, 2, 2, 5, 2, 1], [1, 0, 2, 2, 1, 0], [2, 0, 4, 5, 2, 0], [1, 1, 2, 2, 2, 0], [2, 0, 3, 4, 1, 1], [0, 0, 2, 4, 0, 2], [2, 0, 5, 5, 2, 2], [0, 1, 5, 5, 2, 1], [0, 1, 3, 5, 1, 2], [2, 2, 2, 5, 1, 0], [0, 0, 5, 2, 0, 2], [2, 0, 3, 2, 2, 1], [1, 0, 4, 5, 2, 1], [2, 1, 5, 4, 0, 1], [2, 1, 3, 4, 2, 2], [2, 0, 5, 5, 1, 0], [0, 0, 5, 2, 2, 1], [0, 0, 3, 4, 0, 2], [2, 0, 2, 2, 0, 0], [0, 0, 3, 2, 0, 0], [0, 2, 5, 4, 2, 0], [0, 1, 3, 4, 0, 0], [0, 2, 2, 2, 1, 0], [1, 2, 4, 4, 0, 2], [0, 2, 5, 5, 1, 2], [0, 1, 5, 2, 1, 1], [0, 0, 2, 2, 2, 0], [1, 1, 2, 5, 2, 1], [2, 0, 4, 5, 2, 2], [0, 1, 2, 5, 2, 2], [0, 0, 4, 2, 1, 0], [2, 0, 3, 2, 0, 0], [1, 1, 5, 5, 1, 2], [1, 0, 3, 5, 0, 2], [2, 0, 4, 4, 1, 2], [0, 0, 5, 2, 1, 1], [2, 2, 5, 4, 0, 1], [0, 0, 5, 4, 2, 1], [2, 0, 2, 5, 2, 0], [1, 0, 2, 5, 1, 2], [0, 2, 4, 4, 0, 1], [0, 0, 2, 5, 2, 1], [0, 1, 4, 2, 1, 0], [2, 2, 3, 5, 2, 1], [1, 2, 2, 5, 0, 1], [2, 0, 3, 2, 1, 1], [1, 0, 2, 2, 1, 0], [0, 1, 3, 4, 0, 0], [1, 1, 2, 2, 0, 0], [0, 2, 3, 2, 1, 0], [0, 0, 4, 2, 1, 1], [0, 0, 2, 4, 1, 0], [0, 0, 3, 2, 1, 2], [1, 2, 3, 4, 1, 1], [0, 0, 2, 2, 0, 1], [0, 1, 3, 5, 1, 1], [2, 2, 4, 5, 0, 0], [0, 1, 5, 2, 0, 0], [2, 0, 4, 2, 0, 1], [0, 0, 3, 5, 2, 2], [1, 0, 5, 2, 0, 1], [0, 0, 5, 4, 1, 0], [2, 0, 3, 5, 2, 0], [1, 1, 4, 4, 0, 1], [0, 0, 2, 5, 1, 0], [0, 2, 2, 2, 0, 1], [2, 0, 2, 2, 2, 2], [0, 0, 4, 5, 1, 1], [2, 1, 4, 4, 1, 0], [1, 1, 3, 4, 2, 0], [0, 1, 5, 2, 2, 2], [2, 2, 3, 5, 1, 1], [2, 0, 3, 4, 1, 2], [1, 0, 3, 5, 2, 2], [1, 1, 3, 4, 1, 2], [0, 2, 2, 2, 0, 1], [1, 2, 5, 2, 0, 2], [1, 0, 4, 4, 2, 0], [1, 1, 4, 2, 1, 2], [0, 1, 5, 2, 1, 0], [2, 2, 2, 5, 2, 0], [0, 2, 5, 2, 0, 0], [1, 0, 5, 4, 0, 0], [0, 0, 4, 4, 2, 1], [0, 0, 2, 2, 2, 0], [0, 0, 4, 4, 2, 0], [0, 0, 4, 4, 0, 1], [0, 0, 2, 2, 0, 2], [0, 2, 4, 4, 0, 0], [1, 1, 2, 4, 0, 1], [0, 0, 4, 5, 2, 2], [0, 0, 3, 5, 2, 1], [0, 0, 4, 2, 1, 1], [2, 0, 3, 4, 2, 1], [0, 1, 4, 4, 1, 2], [0, 2, 2, 2, 2, 0], [1, 2, 4, 2, 1, 1], [1, 2, 4, 5, 2, 1], [2, 1, 5, 4, 0, 2], [2, 0, 4, 4, 0, 1], [0, 2, 2, 4, 1, 1], [0, 1, 5, 4, 2, 2], [0, 0, 2, 4, 2, 0], [0, 0, 2, 2, 2, 2], [0, 0, 3, 4, 2, 1], [0, 0, 4, 4, 2, 2], [1, 0, 4, 2, 2, 0], [0, 2, 3, 4, 2, 1], [1, 0, 4, 2, 1, 0], [0, 0, 3, 2, 1, 0], [1, 1, 4, 5, 0, 1], [1, 0, 5, 4, 1, 0], [1, 2, 2, 4, 1, 0], [0, 0, 5, 4, 1, 2], [0, 2, 2, 2, 2, 1], [0, 0, 3, 5, 2, 0], [0, 0, 4, 4, 0, 0], [1, 1, 5, 2, 1, 2], [0, 2, 4, 2, 0, 0], [2, 2, 3, 4, 2, 1], [0, 1, 5, 4, 2, 0], [2, 0, 2, 5, 1, 1], [0, 2, 4, 2, 0, 1]] \n",
    "labels=[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 3, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 1, 1, 0, 3, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 3, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 1, 2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 3, 0, 0, 3, 3, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 3, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 3, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 3, 0, 1, 3, 0, 0, 0, 1, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 0, 0, 0, 3, 0, 3, 1, 1, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 1, 0, 1, 3, 3, 1, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 3, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 2, 1, 3, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 3, 0, 0, 1, 1, 3, 0, 0, 3, 1, 1, 0, 0, 0, 0, 1, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 3, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "\n",
    "#print(features, labels)\n",
    "dTree = decision_tree.DecisionTree()\n",
    "dTree.train(features, labels)\n",
    "\n",
    "# print\n",
    "Utils.print_tree(dTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "X_test, y_test = data.sample_decision_tree_test()\n",
    "y_test=[0,0,1]\n",
    "dTree = decision_tree.DecisionTree()\n",
    "dTree.train(X_test, y_test)\n",
    "# testing\n",
    "print(X_test,y_test)\n",
    "y_est_test = dTree.predict(X_test)\n",
    "print( y_est_test)\n",
    "\n",
    "# print\n",
    "Utils.print_tree(dTree)\n",
    "test_accu = accuracy_score(y_est_test, y_test)\n",
    "# print\n",
    "#Utils.print_tree(dTree)\n",
    "print('test_accu', test_accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.3 Train and Predict\n",
    "### 2.3.1\n",
    "- Load data (features and values) from function data.load_decision_tree_data.\n",
    "- Train your decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "X_train, y_train, X_test, y_test = data.load_decision_tree_data()\n",
    "X_train=X_train.tolist()\n",
    "y_train=y_train.tolist()\n",
    "X_test=X_test.tolist()\n",
    "y_test=y_test.tolist()\n",
    "\n",
    "\n",
    "\n",
    "#X_train=[['Sunny', 'High', 'Strong'], ['Sunny', 'Normal', 'Strong'], ['Overcast', 'High', 'Strong'], ['Overcast', 'Normal', 'Weak'], ['Overcast', 'High', 'Strong'], ['Overcast', 'Normal', 'Weak'], ['Overcast', 'High', 'Strong'], ['Overcast', 'Normal', 'Weak'], ['Rain', 'Normal', 'Strong'], ['Rain', 'Normal', 'Weak']] \n",
    "#y_train=[0, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
    "\n",
    "#X_test=[['Sunny', 'Normal', 'Strong'], ['Sunny', 'Normal', 'Strong'], ['Sunny', 'Normal', 'Strong'], ['Sunny', 'High', 'Strong'], ['Sunny', 'High', 'Strong'],['Overcast', 'Normal', 'Weak'], ['Overcast', 'High', 'Strong'], ['Overcast', 'Normal', 'Weak'], ['Overcast', 'High', 'Strong'], ['Overcast', 'Normal', 'Weak'], ['Rain', 'Normal', 'Strong'], ['Rain', 'Normal', 'Strong'], ['Rain', 'Normal', 'Weak'],['Rain', 'Normal', 'Weak'],['Rain', 'Normal', 'Weak'],['Rain', 'Normal', 'Weak']]\n",
    "\n",
    "#y_test=[1, 1, 0, 0, 0, 1, 1, 1, 0, 0,1,1,1,1,0,0 ]\n",
    "\n",
    "# set classifier\n",
    "dTree = decision_tree.DecisionTree()\n",
    "\n",
    "# training\n",
    "dTree.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2\n",
    "- Print your decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print\n",
    "Utils.print_tree(dTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3\n",
    "- do prediction on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# testing\n",
    "dTree.root_node.expectedLabels=y_test\n",
    "y_est_test = dTree.predict(X_test)\n",
    "test_accu = accuracy_score(y_est_test, y_test)\n",
    "print('test_accu', test_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.print_tree(dTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.4 Pruning The Tree\n",
    "Sometimes, in order to prevent overfitting. We need to pruning our Decition Tree. There are several approaches to avoiding overfitting in building decision trees. \n",
    "\n",
    "- Pre-pruning that stop growing the tree earlier, before it perfectly classifies the training set.\n",
    "- Post-pruning that allows the tree to perfectly classify the training set, and then post prune the tree. \n",
    "\n",
    "Practically, the second approach of post-pruning overfit trees is more successful because it is not easy to precisely estimate when to stop growing the tree.\n",
    "We will use Reduced Error Pruning, as one of Post-pruning in this part.\n",
    "```\n",
    "Reduced Error Pruning\n",
    "0. Split data into training and validation sets.\n",
    "1. Do until further pruning is harmful:\n",
    "2. Evaluate impact on validation set of pruning each possible node (plus those below it)\n",
    "3. Greedily remove the one that most improves validation set accuracy\n",
    "- Produces smallest version of most accurate subtree.\n",
    "- Requires that a lot of data be available.\n",
    "```\n",
    "For Pruning of Decision Tree, you can refer [Reduce Error Pruning](http://jmvidal.cse.sc.edu/talks/decisiontrees/reducederrorprun.html?style=White) and P69 of Textbook: Machine Learning -Tom Mitchell.\n",
    "\n",
    "### 2.4.1 \n",
    "**Hint: in this part, you can add another parameters or functions in TreeNode class and DecisionTree class for your convenience. But your changes should not influent results of previous parts.**<br>\n",
    "implement the reduced_error_pruning function on util.py.\n",
    "\n",
    "```\n",
    "def reduced_error_pruning(decitionTree):\n",
    "# input: \n",
    "    - decitionTree: decitionTree trained based on training data set.\n",
    "    - X_test: List[List[any]] test data, num_cases*num_attributes\n",
    "    - y_test: List[any] test labels, num_cases*1\n",
    "```\n",
    "\n",
    "Note: To prune from a node, simply set its children to an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utils.print_tree(dTree)\n",
    "Utils.reduced_error_prunning(dTree, X_test, y_test)\n",
    "#Utils.print_tree(dTree)\n",
    "#dTree.root_node.zeroOutCorrectPredictions()\n",
    "#Utils.print_tree(dTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2\n",
    "Test your prediction accuracy on validation dataset after pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est_test = dTree.predict(X_test)\n",
    "test_accu = accuracy_score(y_est_test, y_test)\n",
    "print('test_accu', test_accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3\n",
    "Print your decision tree after pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.print_tree(dTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidline\n",
    "1. Information_Gain function - 10 points <br>\n",
    "we will test your Infomation Gain function on another ten inputs. To receive full credits of this part, your function should be able to output right valus.\n",
    "2. Train your decision tree - 15 points <br>\n",
    "we will test your decision tree after training on training dataset. To receive full credit of this part, your algorithm will generate the identical decision tree as our answer.\n",
    "3. Prediction of decision tree - 10 points <br>\n",
    "we will use another dataset to test your prediction part of decision tree, you can assume that test dataset has identical attributs and values as traning dataset. To receive full credit of this part, your algorithm will generate the identical prediction of our answer.\n",
    "4. Pruning of decision tree - 15 points <br>\n",
    "we will test your decision tree after pruning. To receive full credit of this part, your algorithm will generate the identical decision tree as our answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good Luck! : )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
